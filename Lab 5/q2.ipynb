{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ca943bab-7c03-4746-9d47-69acf20e7493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bc71c8eb-c412-449c-bd36-39ddc297ce51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image= tensor([[0.3078, 0.4288, 0.0950, 0.1050, 0.1800, 0.1858],\n",
      "        [0.8429, 0.8250, 0.7929, 0.6794, 0.3081, 0.8810],\n",
      "        [0.8823, 0.4399, 0.9410, 0.7737, 0.3451, 0.7679],\n",
      "        [0.4952, 0.6465, 0.8562, 0.1271, 0.1760, 0.5567],\n",
      "        [0.4177, 0.8356, 0.8338, 0.0354, 0.7595, 0.5734],\n",
      "        [0.6522, 0.6027, 0.8864, 0.4029, 0.4545, 0.5873]])\n"
     ]
    }
   ],
   "source": [
    "image = torch.rand(6,6)\n",
    "print(\"image=\", image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8077e7d8-e17a-4471-8969-2d56d5a7e9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape = torch.Size([1, 1, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "image = image.unsqueeze(dim=0)\n",
    "image = image.unsqueeze(dim=0)\n",
    "print(\"image.shape =\", image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9c519e84-6562-432c-8c7e-36596103aefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image = tensor([[[[0.3078, 0.4288, 0.0950, 0.1050, 0.1800, 0.1858],\n",
      "          [0.8429, 0.8250, 0.7929, 0.6794, 0.3081, 0.8810],\n",
      "          [0.8823, 0.4399, 0.9410, 0.7737, 0.3451, 0.7679],\n",
      "          [0.4952, 0.6465, 0.8562, 0.1271, 0.1760, 0.5567],\n",
      "          [0.4177, 0.8356, 0.8338, 0.0354, 0.7595, 0.5734],\n",
      "          [0.6522, 0.6027, 0.8864, 0.4029, 0.4545, 0.5873]]]])\n"
     ]
    }
   ],
   "source": [
    "print(\"image =\", image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9d6bc1e5-859e-4cb9-9d06-4a70b95e4e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outimage = tensor([[[[-0.2501, -0.1563, -0.3885, -0.1725],\n",
      "          [-0.4870, -0.7009, -0.6509, -0.4185],\n",
      "          [-0.4184, -0.8523, -0.4219, -0.2684],\n",
      "          [-0.4614, -0.5085, -0.2928, -0.2593]],\n",
      "\n",
      "         [[-0.5081, -0.3845, -0.4944, -0.5731],\n",
      "          [-0.4594, -0.1314, -0.4579, -0.5287],\n",
      "          [-0.3455, -0.2907, -0.6166, -0.2369],\n",
      "          [-0.3641, -0.2698, -0.5758, -0.2752]],\n",
      "\n",
      "         [[ 0.1107,  0.2714,  0.0801, -0.0226],\n",
      "          [ 0.0919, -0.0846, -0.1968,  0.1120],\n",
      "          [ 0.1621,  0.0177, -0.3015, -0.0341],\n",
      "          [ 0.1704,  0.0442, -0.3529,  0.1064]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "\n",
      "Output image dimension :  torch.Size([1, 3, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "conv = nn.Conv2d(1, 3, 3, stride=1)\n",
    "out1 = conv(image)\n",
    "print(\"outimage =\", out1)\n",
    "print(\"\\nOutput image dimension : \", out1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4f511545-e90c-4947-b4bd-b4a569584ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outimage = tensor([[[[5.5557, 5.0807, 4.2203, 4.2261],\n",
      "          [6.7218, 6.0816, 4.9995, 4.6151],\n",
      "          [6.3481, 5.4891, 4.8478, 4.1149],\n",
      "          [6.2262, 5.2265, 4.5318, 3.6728]],\n",
      "\n",
      "         [[5.5557, 5.0807, 4.2203, 4.2261],\n",
      "          [6.7218, 6.0816, 4.9995, 4.6151],\n",
      "          [6.3481, 5.4891, 4.8478, 4.1149],\n",
      "          [6.2262, 5.2265, 4.5318, 3.6728]],\n",
      "\n",
      "         [[5.5557, 5.0807, 4.2203, 4.2261],\n",
      "          [6.7218, 6.0816, 4.9995, 4.6151],\n",
      "          [6.3481, 5.4891, 4.8478, 4.1149],\n",
      "          [6.2262, 5.2265, 4.5318, 3.6728]]]])\n",
      "\n",
      "Output image dimension :  torch.Size([1, 3, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "kernel=torch.ones(3,1,3,3)\n",
    "out2 = F.conv2d(image,kernel, stride=1)\n",
    "print(\"outimage =\", out2)\n",
    "print(\"\\nOutput image dimension : \", out2.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
